#!/usr/bin/env python
# train_ocsvm_gui.py

import tkinter as tk
from tkinter import ttk, messagebox, scrolledtext
import psycopg2
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import joblib
import json
import os
import threading
from sklearn.svm import OneClassSVM
import optuna
from optuna import create_study
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

# ë¼ì¦ˆë² ë¦¬íŒŒì´ì˜ CustomRobustScaler êµ¬í˜„
class CustomRobustScaler:
    def __init__(self):
        self.params = {}
    
    def fit(self, X):
        self.params = {}
        for i in range(X.shape[1]):
            col = X[:, i]
            q1, median, q3 = np.percentile(col, [25, 50, 75])
            iqr = q3 - q1
            self.params[i] = {'median': median, 'iqr': iqr}
    
    def transform(self, X):
        X_scaled = np.zeros_like(X, dtype=np.float64)
        for i in range(X.shape[1]):
            median = self.params[i]['median']
            iqr = self.params[i]['iqr']
            X_scaled[:, i] = (X[:, i] - median) / iqr
        return X_scaled
    
    def fit_transform(self, X):
        self.fit(X)
        return self.transform(X)
    
    def save(self, filepath):
        joblib.dump({"params": self.params}, filepath)
    
    def load(self, filepath):
        loaded = joblib.load(filepath)
        self.params = loaded["params"]
        
class OCSVMTrainerGUI:
    def __init__(self, root):
        self.root = root
        self.root.title("OCSVM ëª¨ë¸ í•™ìŠµ ë„êµ¬")
        self.root.geometry("1400x900")
        
        # ë¡œê·¸ í…ìŠ¤íŠ¸ ìœ„ì ¯ì„ ë¨¼ì € ì´ˆê¸°í™”
        self.log_text = None
        
        # DB ì—°ê²°
        self.conn = None
        
        # ì„¤ì •ê°’
        self.sensor_config = {
            "mic": {
                "sampling_rate": 8000,
                "window_sec": 5,
                "features": ["mav", "rms", "peak", "amp_iqr"],
                "nu_range": [0.01, 0.15],
                "gamma_range": [0.0001, 0.005]
            },
            "acc": {
                "sampling_rate": 1666,
                "window_sec": 5,
                "features": ["x_peak", "x_crest_factor", "y_peak", "y_crest_factor", "z_peak", "z_crest_factor"],
                "nu_range": [0.01, 0.15],
                "gamma_range": [0.0001, 0.005]
            }
        }
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ê¸°ê°„ ì €ì¥
        self.training_periods = []
        self.test_periods = []
        
        # GUI ìƒì„±
        self.create_widgets()
        
        # DB ì—°ê²° (GUI ìƒì„± í›„)
        self.connect_db()
        
        # ë‚ ì§œ ë²”ìœ„ ë¡œë“œ
        self.load_date_range()
    
    def log(self, message):
        """ë¡œê·¸ ë©”ì‹œì§€ ì¶œë ¥"""
        if self.log_text:
            timestamp = datetime.now().strftime("%H:%M:%S")
            self.log_text.insert(tk.END, f"[{timestamp}] {message}\n")
            self.log_text.see(tk.END)
            self.root.update()
        else:
            print(f"[LOG] {message}")  # ë¡œê·¸ ìœ„ì ¯ì´ ì—†ì„ ë•Œ ì½˜ì†” ì¶œë ¥
    
    def connect_db(self):
        """DB ì—°ê²° - íŠ¸ëœì­ì…˜ ì—ëŸ¬ ë°©ì§€"""
        try:
            self.conn = psycopg2.connect(
                host='localhost',
                port='5432',
                database='pdm_db',
                user='pdm_user',
                password='pdm_password'
            )
            # autocommit ì„¤ì •ìœ¼ë¡œ íŠ¸ëœì­ì…˜ ì—ëŸ¬ ë°©ì§€
            self.conn.autocommit = True
            self.log("âœ… DB ì—°ê²° ì„±ê³µ")
            
            # í…Œì´ë¸” ë° ë°ì´í„° í™•ì¸
            cur = self.conn.cursor()
            
            # í…Œì´ë¸” í™•ì¸
            cur.execute("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name IN ('normal_acc_data', 'normal_mic_data')
            """)
            tables = [row[0] for row in cur.fetchall()]
            self.log(f"í™•ì¸ëœ í…Œì´ë¸”: {tables}")
            
            # ê° í…Œì´ë¸”ì˜ ë°ì´í„° ìˆ˜ í™•ì¸
            for table in tables:
                cur.execute(f"SELECT COUNT(*) FROM {table}")
                count = cur.fetchone()[0]
                self.log(f"{table}: {count:,}ê°œ ë ˆì½”ë“œ")
            
            # ë¨¸ì‹ ë³„ ë°ì´í„° í™•ì¸
            for table in tables:
                cur.execute(f"""
                    SELECT machine_id, COUNT(*) as cnt, 
                           MIN(time) as min_time, MAX(time) as max_time
                    FROM {table}
                    GROUP BY machine_id
                """)
                for row in cur.fetchall():
                    self.log(f"{table} - {row[0]}: {row[1]:,}ê°œ, {row[2]} ~ {row[3]}")
            
        except Exception as e:
            self.log(f"DB ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            messagebox.showerror("DB ì—°ê²° ì‹¤íŒ¨", str(e))
    
    def create_widgets(self):
        # ë©”ì¸ ë…¸íŠ¸ë¶
        notebook = ttk.Notebook(self.root)
        notebook.pack(fill='both', expand=True, padx=5, pady=5)
        
        # í•™ìŠµ íƒ­
        train_tab = ttk.Frame(notebook)
        notebook.add(train_tab, text="ëª¨ë¸ í•™ìŠµ")
        self.create_train_tab(train_tab)
        
        # í…ŒìŠ¤íŠ¸ íƒ­
        test_tab = ttk.Frame(notebook)
        notebook.add(test_tab, text="ëª¨ë¸ í…ŒìŠ¤íŠ¸")
        self.create_test_tab(test_tab)
        
        # ë¡œê·¸ íƒ­
        log_tab = ttk.Frame(notebook)
        notebook.add(log_tab, text="ë¡œê·¸")
        self.create_log_tab(log_tab)
    
    def create_train_tab(self, parent):
        # ì„¤ì • í”„ë ˆì„
        config_frame = ttk.LabelFrame(parent, text="í•™ìŠµ ì„¤ì •", padding="10")
        config_frame.pack(fill='x', padx=5, pady=5)
        
        # ë¨¸ì‹ /ì„¼ì„œ ì„ íƒ
        row = 0
        ttk.Label(config_frame, text="ë¨¸ì‹ :").grid(row=row, column=0, sticky=tk.W, padx=5)
        self.machine_var = tk.StringVar(value="CURINGOVEN_M1")
        machine_combo = ttk.Combobox(config_frame, textvariable=self.machine_var, 
                                    values=["CURINGOVEN_M1", "HOTCHAMBER_M2"], width=20)
        machine_combo.grid(row=row, column=1, padx=5)
        
        ttk.Label(config_frame, text="ì„¼ì„œ:").grid(row=row, column=2, sticky=tk.W, padx=5)
        self.sensor_var = tk.StringVar(value="acc")
        sensor_combo = ttk.Combobox(config_frame, textvariable=self.sensor_var,
                                   values=["acc", "mic"], width=10)
        sensor_combo.grid(row=row, column=3, padx=5)
        
        # ìµœì í™” ì„¤ì •
        row += 1
        ttk.Label(config_frame, text="Optuna Trials:").grid(row=row, column=0, sticky=tk.W, padx=5)
        self.trials_var = tk.IntVar(value=50)
        trials_spinbox = ttk.Spinbox(config_frame, from_=10, to=500, increment=10,
                                    textvariable=self.trials_var, width=10)
        trials_spinbox.grid(row=row, column=1, padx=5)
        
        # í•™ìŠµ ê¸°ê°„ í”„ë ˆì„
        period_frame = ttk.LabelFrame(parent, text="í•™ìŠµ ê¸°ê°„ ì„¤ì •", padding="10")
        period_frame.pack(fill='both', expand=True, padx=5, pady=5)
        
        # ê¸°ê°„ ì…ë ¥
        input_frame = ttk.Frame(period_frame)
        input_frame.pack(fill='x')
        
        ttk.Label(input_frame, text="ì‹œì‘ì¼:").pack(side='left', padx=5)
        self.train_start_date = ttk.Entry(input_frame, width=12)
        self.train_start_date.pack(side='left', padx=5)
        
        ttk.Label(input_frame, text="ì¢…ë£Œì¼:").pack(side='left', padx=5)
        self.train_end_date = ttk.Entry(input_frame, width=12)
        self.train_end_date.pack(side='left', padx=5)
        
        ttk.Button(input_frame, text="ê¸°ê°„ ì¶”ê°€", 
                  command=self.add_training_period).pack(side='left', padx=20)
        
        # ê¸°ê°„ ëª©ë¡
        list_frame = ttk.Frame(period_frame)
        list_frame.pack(fill='both', expand=True, pady=10)
        
        # íŠ¸ë¦¬ë·°
        columns = ('ì‹œì‘ì¼', 'ì¢…ë£Œì¼', 'ì¼ìˆ˜')
        self.train_tree = ttk.Treeview(list_frame, columns=columns, height=8)
        self.train_tree.heading('#0', text='No')
        self.train_tree.heading('ì‹œì‘ì¼', text='ì‹œì‘ì¼')
        self.train_tree.heading('ì¢…ë£Œì¼', text='ì¢…ë£Œì¼')
        self.train_tree.heading('ì¼ìˆ˜', text='ì¼ìˆ˜')
        
        self.train_tree.column('#0', width=50)
        self.train_tree.column('ì‹œì‘ì¼', width=150)
        self.train_tree.column('ì¢…ë£Œì¼', width=150)
        self.train_tree.column('ì¼ìˆ˜', width=80)
        
        self.train_tree.pack(side='left', fill='both', expand=True)
        
        # ìŠ¤í¬ë¡¤ë°”
        scrollbar = ttk.Scrollbar(list_frame, orient='vertical', command=self.train_tree.yview)
        scrollbar.pack(side='right', fill='y')
        self.train_tree.configure(yscrollcommand=scrollbar.set)
        
        # ë²„íŠ¼ í”„ë ˆì„
        button_frame = ttk.Frame(period_frame)
        button_frame.pack(fill='x')
        
        ttk.Button(button_frame, text="ì„ íƒ ì‚­ì œ", 
                  command=self.remove_training_period).pack(side='left', padx=5)
        ttk.Button(button_frame, text="ëª¨ë‘ ì‚­ì œ", 
                  command=self.clear_training_periods).pack(side='left', padx=5)
        
        # í•™ìŠµ ë²„íŠ¼
        train_button_frame = ttk.Frame(parent)
        train_button_frame.pack(fill='x', padx=5, pady=10)
        
        self.train_button = ttk.Button(train_button_frame, text="ëª¨ë¸ í•™ìŠµ ì‹œì‘", 
                                      command=self.start_training)
        self.train_button.pack(side='left', padx=5)
        
        self.progress_var = tk.StringVar(value="ëŒ€ê¸° ì¤‘...")
        ttk.Label(train_button_frame, textvariable=self.progress_var).pack(side='left', padx=20)
    
    def create_test_tab(self, parent):
        # ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒ í”„ë ˆì„
        model_frame = ttk.LabelFrame(parent, text="ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒ", padding="10")
        model_frame.pack(fill='x', padx=5, pady=5)
        
        # ì„¼ì„œ íƒ€ì… ì„ íƒ
        ttk.Label(model_frame, text="ì„¼ì„œ íƒ€ì…:").grid(row=0, column=0, sticky=tk.W, padx=5)
        self.test_sensor_var = tk.StringVar(value="acc")
        sensor_radio_frame = ttk.Frame(model_frame)
        sensor_radio_frame.grid(row=0, column=1, columnspan=2, sticky=tk.W, padx=5)
        
        ttk.Radiobutton(sensor_radio_frame, text="ê°€ì†ë„ ì„¼ì„œ", variable=self.test_sensor_var, 
                        value="acc", command=self.update_test_settings).pack(side='left', padx=5)
        ttk.Radiobutton(sensor_radio_frame, text="ë§ˆì´í¬ ì„¼ì„œ", variable=self.test_sensor_var, 
                        value="mic", command=self.update_test_settings).pack(side='left', padx=5)
        
        # ëª¨ë¸ íŒŒì¼ ì„ íƒ
        ttk.Label(model_frame, text="ëª¨ë¸ íŒŒì¼:").grid(row=1, column=0, sticky=tk.W, padx=5)
        self.model_file_var = tk.StringVar()
        ttk.Entry(model_frame, textvariable=self.model_file_var, width=50).grid(row=1, column=1, padx=5)
        ttk.Button(model_frame, text="ì°¾ì•„ë³´ê¸°", 
                  command=self.browse_model_file).grid(row=1, column=2, padx=5)
        
        # ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ì„ íƒ
        ttk.Label(model_frame, text="ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼:").grid(row=2, column=0, sticky=tk.W, padx=5)
        self.scaler_file_var = tk.StringVar()
        ttk.Entry(model_frame, textvariable=self.scaler_file_var, width=50).grid(row=2, column=1, padx=5)
        ttk.Button(model_frame, text="ì°¾ì•„ë³´ê¸°", 
                  command=self.browse_scaler_file).grid(row=2, column=2, padx=5)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • í”„ë ˆì„
        db_frame = ttk.LabelFrame(parent, text="ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •", padding="10")
        db_frame.pack(fill='x', padx=5, pady=5)
        
        # ë¨¸ì‹  ì„ íƒ
        ttk.Label(db_frame, text="ë¨¸ì‹ :").grid(row=0, column=0, sticky=tk.W, padx=5)
        self.test_machine_var = tk.StringVar(value="CURINGOVEN_M1")
        ttk.Combobox(db_frame, textvariable=self.test_machine_var, 
                    values=["CURINGOVEN_M1", "HOTCHAMBER_M2"], 
                    width=20).grid(row=0, column=1, padx=5)
        
        # ìƒ˜í”Œë§ ì„¤ì • í‘œì‹œ
        ttk.Label(db_frame, text="ìƒ˜í”Œë§ ì„¤ì •:").grid(row=1, column=0, sticky=tk.W, padx=5)
        self.sampling_info_var = tk.StringVar(value="ê°€ì†ë„: 1666Hz, 5ì´ˆ ìœˆë„ìš°")
        ttk.Label(db_frame, textvariable=self.sampling_info_var).grid(row=1, column=1, sticky=tk.W, padx=5)
        
        # íŠ¹ì§• ì •ë³´ í‘œì‹œ
        ttk.Label(db_frame, text="ì¶”ì¶œ íŠ¹ì§•:").grid(row=2, column=0, sticky=tk.W, padx=5)
        self.features_info_var = tk.StringVar(value="x_peak, x_crest_factor, y_peak, y_crest_factor, z_peak, z_crest_factor")
        features_label = ttk.Label(db_frame, textvariable=self.features_info_var, wraplength=400)
        features_label.grid(row=2, column=1, sticky=tk.W, padx=5)
        
        # í…ŒìŠ¤íŠ¸ ê¸°ê°„ í”„ë ˆì„
        test_period_frame = ttk.LabelFrame(parent, text="í…ŒìŠ¤íŠ¸ ê¸°ê°„ ì„¤ì •", padding="10")
        test_period_frame.pack(fill='both', expand=True, padx=5, pady=5)
        
        # ê¸°ê°„ ì…ë ¥
        test_input_frame = ttk.Frame(test_period_frame)
        test_input_frame.pack(fill='x')
        
        ttk.Label(test_input_frame, text="ë‚ ì§œ:").pack(side='left', padx=5)
        self.test_date = ttk.Entry(test_input_frame, width=12)
        self.test_date.pack(side='left', padx=5)
        
        ttk.Button(test_input_frame, text="ë‚ ì§œ ì¶”ê°€", 
                  command=self.add_test_date).pack(side='left', padx=20)
        
        # í…ŒìŠ¤íŠ¸ ë‚ ì§œ ëª©ë¡
        self.test_listbox = tk.Listbox(test_period_frame, height=8)
        self.test_listbox.pack(fill='both', expand=True, pady=10)
        
        # ë²„íŠ¼
        test_button_frame = ttk.Frame(test_period_frame)
        test_button_frame.pack(fill='x')
        
        ttk.Button(test_button_frame, text="ì„ íƒ ì‚­ì œ", 
                  command=self.remove_test_date).pack(side='left', padx=5)
        ttk.Button(test_button_frame, text="ëª¨ë‘ ì‚­ì œ", 
                  command=self.clear_test_dates).pack(side='left', padx=5)
        
        # í…ŒìŠ¤íŠ¸ ì‹œì‘ ë²„íŠ¼
        ttk.Button(parent, text="í…ŒìŠ¤íŠ¸ ì‹œì‘", 
                  command=self.start_testing).pack(pady=10)
        
        # ê²°ê³¼ í‘œì‹œ
        result_frame = ttk.LabelFrame(parent, text="í…ŒìŠ¤íŠ¸ ê²°ê³¼", padding="10")
        result_frame.pack(fill='both', expand=True, padx=5, pady=5)
        
        self.result_text = scrolledtext.ScrolledText(result_frame, height=10)
        self.result_text.pack(fill='both', expand=True)
    
    def create_log_tab(self, parent):
        # ë¡œê·¸ í…ìŠ¤íŠ¸ ìœ„ì ¯ ìƒì„±
        self.log_text = scrolledtext.ScrolledText(parent, height=30)
        self.log_text.pack(fill='both', expand=True, padx=5, pady=5)
    
    def update_test_settings(self):
        """ì„¼ì„œ íƒ€ì…ì— ë”°ë¼ ì„¤ì • ì •ë³´ ì—…ë°ì´íŠ¸"""
        sensor = self.test_sensor_var.get()
        if sensor == "acc":
            self.sampling_info_var.set("ê°€ì†ë„: 1666Hz, 5ì´ˆ ìœˆë„ìš°")
            self.features_info_var.set("x_peak, x_crest_factor, y_peak, y_crest_factor, z_peak, z_crest_factor")
        else:
            self.sampling_info_var.set("ë§ˆì´í¬: 8000Hz, 5ì´ˆ ìœˆë„ìš°")
            self.features_info_var.set("mav, rms, peak, amp_iqr")
    
    def browse_model_file(self):
        """ëª¨ë¸ íŒŒì¼ ì°¾ì•„ë³´ê¸°"""
        from tkinter import filedialog
        filename = filedialog.askopenfilename(
            title="ëª¨ë¸ íŒŒì¼ ì„ íƒ",
            initialdir="./models",
            filetypes=[("Pickle files", "*.pkl"), ("All files", "*.*")]
        )
        if filename:
            self.model_file_var.set(filename)
            
            # ëª¨ë¸ ì •ë³´ íŒŒì¼ë„ ê°™ì´ ì°¾ê¸°
            info_path = filename.replace('_model.pkl', '_model_info.json')
            if os.path.exists(info_path):
                with open(info_path, 'r') as f:
                    model_info = json.load(f)
                    # ì„¼ì„œ íƒ€ì… ìë™ ì„¤ì •
                    self.test_sensor_var.set(model_info.get('sensor', 'acc'))
                    self.update_test_settings()
    
    def browse_scaler_file(self):
        """ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ì°¾ì•„ë³´ê¸°"""
        from tkinter import filedialog
        filename = filedialog.askopenfilename(
            title="ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ì„ íƒ",
            initialdir="./models",
            filetypes=[("Pickle files", "*.pkl"), ("All files", "*.*")]
        )
        if filename:
            self.scaler_file_var.set(filename)
    
    def load_date_range(self):
        """DBì—ì„œ ë°ì´í„° ë‚ ì§œ ë²”ìœ„ í™•ì¸"""
        try:
            cur = self.conn.cursor()
            cur.execute("""
                SELECT MIN(DATE(time)), MAX(DATE(time))
                FROM normal_acc_data
            """)
            min_date, max_date = cur.fetchone()
            
            if min_date and max_date:
                self.train_start_date.insert(0, min_date.strftime("%Y-%m-%d"))
                self.train_end_date.insert(0, max_date.strftime("%Y-%m-%d"))
                self.test_date.insert(0, max_date.strftime("%Y-%m-%d"))
                
                self.log(f"ë°ì´í„° ë²”ìœ„: {min_date} ~ {max_date}")
        except Exception as e:
            self.log(f"ë‚ ì§œ ë²”ìœ„ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def check_data_exists(self):
        """ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        try:
            cur = self.conn.cursor()
            
            # ê° í…Œì´ë¸”ì˜ ë°ì´í„° ìˆ˜ í™•ì¸
            for table in ['acc_data', 'mic_data']:
                cur.execute(f"SELECT COUNT(*) FROM {table}")
                count = cur.fetchone()[0]
                self.log(f"{table}: {count}ê°œ ë ˆì½”ë“œ")
                
            # ë¨¸ì‹ ë³„ ë°ì´í„° ìˆ˜ í™•ì¸
            for table in ['acc_data', 'mic_data']:
                cur.execute(f"""
                    SELECT machine_id, COUNT(*), MIN(time), MAX(time)
                    FROM {table}
                    GROUP BY machine_id
                """)
                for row in cur.fetchall():
                    self.log(f"{table} - {row[0]}: {row[1]}ê°œ, {row[2]} ~ {row[3]}")
                    
        except Exception as e:
            self.log(f"ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}")
    
    def stratified_time_sampling(self, X_scaled, period_info, target_size):
        """ì‹œê°„ëŒ€ë³„ ê· ë“± ìƒ˜í”Œë§"""
        sample_indices = []
        
        # ê° ê¸°ê°„ì„ ì‹œê°„ëŒ€ë³„ë¡œ ë‚˜ëˆ„ê¸°
        for info in period_info:
            period_data_count = info['count']
            period_sample_size = int(target_size * (period_data_count / len(X_scaled)))
            
            if period_sample_size > 0:
                # í•˜ë£¨ë¥¼ 4ê°œ ì‹œê°„ëŒ€ë¡œ ë‚˜ëˆ„ê¸° (6ì‹œê°„ ë‹¨ìœ„)
                # ë˜ëŠ” í”¼í¬/ì˜¤í”„í”¼í¬ ì‹œê°„ëŒ€ë¡œ ë‚˜ëˆ„ê¸°
                period_start = info['start_idx']
                period_end = info['end_idx']
                
                # ê· ë“± ê°„ê²©ìœ¼ë¡œ ìƒ˜í”Œë§
                indices = np.linspace(period_start, period_end-1, 
                                    period_sample_size, dtype=int)
                sample_indices.extend(indices)
        
        return np.array(sample_indices)
    
    def add_training_period(self):
        try:
            start = self.train_start_date.get()
            end = self.train_end_date.get()
            
            start_date = datetime.strptime(start, "%Y-%m-%d")
            end_date = datetime.strptime(end, "%Y-%m-%d")
            
            if start_date >= end_date:
                messagebox.showerror("ì˜¤ë¥˜", "ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤.")
                return
            
            days = (end_date - start_date).days + 1
            
            # íŠ¸ë¦¬ì— ì¶”ê°€
            item_id = self.train_tree.insert('', 'end', 
                                           text=str(len(self.training_periods) + 1),
                                           values=(start, end, days))
            
            self.training_periods.append((start, end))
            self.log(f"í•™ìŠµ ê¸°ê°„ ì¶”ê°€: {start} ~ {end} ({days}ì¼)")
            
        except ValueError:
            messagebox.showerror("ì˜¤ë¥˜", "ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (YYYY-MM-DD)")
    
    def remove_training_period(self):
        selected = self.train_tree.selection()
        if selected:
            for item in selected:
                idx = self.train_tree.index(item)
                del self.training_periods[idx]
                self.train_tree.delete(item)
            
            # ë²ˆí˜¸ ì¬ì •ë ¬
            for i, item in enumerate(self.train_tree.get_children()):
                self.train_tree.item(item, text=str(i + 1))
    
    def clear_training_periods(self):
        self.training_periods.clear()
        for item in self.train_tree.get_children():
            self.train_tree.delete(item)
    
    def add_test_date(self):
        date = self.test_date.get()
        try:
            datetime.strptime(date, "%Y-%m-%d")
            if date not in self.test_listbox.get(0, tk.END):
                self.test_listbox.insert(tk.END, date)
                self.test_periods.append(date)
        except ValueError:
            messagebox.showerror("ì˜¤ë¥˜", "ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (YYYY-MM-DD)")
    
    def remove_test_date(self):
        selected = self.test_listbox.curselection()
        for idx in reversed(selected):
            self.test_listbox.delete(idx)
            del self.test_periods[idx]
    
    def clear_test_dates(self):
        self.test_listbox.delete(0, tk.END)
        self.test_periods.clear()
    
    def extract_features_acc(self, x_data, y_data, z_data):
        """ACC íŠ¹ì§• ì¶”ì¶œ - ë‹¤ìš´ìƒ˜í”Œë§ëœ ë°ì´í„°ìš©"""
        try:
            # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ìŠ¤í‚µ
            if len(x_data) < 10:
                raise ValueError(f"ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŒ: {len(x_data)}ê°œ")
            
            features = []
            
            # Xì¶•
            x_rms = np.sqrt(np.mean(x_data**2))
            x_peak = np.max(np.abs(x_data))
            x_crest = x_peak / x_rms if x_rms > 1e-10 else 0
            
            # Yì¶•
            y_rms = np.sqrt(np.mean(y_data**2))
            y_peak = np.max(np.abs(y_data))
            y_crest = y_peak / y_rms if y_rms > 1e-10 else 0
            
            # Zì¶•
            z_rms = np.sqrt(np.mean(z_data**2))
            z_peak = np.max(np.abs(z_data))
            z_crest = z_peak / z_rms if z_rms > 1e-10 else 0
            
            return np.array([x_peak, x_crest, y_peak, y_crest, z_peak, z_crest])
            
        except Exception as e:
            self.log(f"ACC íŠ¹ì§• ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            raise
    
    def extract_features_mic(self, mic_data):
        """MIC íŠ¹ì§• ì¶”ì¶œ - ë‹¤ìš´ìƒ˜í”Œë§ëœ ë°ì´í„°ìš©"""
        try:
            # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ìŠ¤í‚µ
            if len(mic_data) < 10:
                raise ValueError(f"ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŒ: {len(mic_data)}ê°œ")
            
            mav = np.mean(np.abs(mic_data))
            rms = np.sqrt(np.mean(mic_data**2))
            peak = np.max(np.abs(mic_data))
            
            # IQR ê³„ì‚° ì‹œ ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ ì¡°ì‹¬
            q1, q3 = np.percentile(np.abs(mic_data), [25, 75])
            amp_iqr = q3 - q1
            
            return np.array([mav, rms, peak, amp_iqr])
            
        except Exception as e:
            self.log(f"MIC íŠ¹ì§• ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            raise
    
    def get_training_data(self, machine_id, sensor, start_date, end_date):
        """DBì—ì„œ í•™ìŠµ ë°ì´í„° ì¶”ì¶œ - ë‹¤ìš´ìƒ˜í”Œë§ëœ ë°ì´í„° ì²˜ë¦¬"""
        window_sec = self.sensor_config[sensor]['window_sec']
        
        # DBì—ëŠ” 1ì´ˆì— 10ê°œì”©ë§Œ ì €ì¥ë˜ì–´ ìˆìŒ
        db_sampling_rate = 10  # 1ì´ˆì— 10ê°œ
        window_samples = window_sec * db_sampling_rate  # 5ì´ˆ * 10 = 50ê°œ
        
        # ì „ì²´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
        if sensor == 'acc':
            query = """
            SELECT time, x, y, z
            FROM normal_acc_data
            WHERE machine_id = %s
            AND time >= %s AND time <= %s
            ORDER BY time
            """
        else:  # mic
            query = """
            SELECT time, mic_value
            FROM normal_mic_data
            WHERE machine_id = %s
            AND time >= %s AND time <= %s
            ORDER BY time
            """
        
        self.log(f"ë°ì´í„° ì¶”ì¶œ ì¤‘: {machine_id}, {sensor}, {start_date} ~ {end_date}")
        
        try:
            df = pd.read_sql(query, self.conn, 
                            params=(machine_id, start_date, end_date))
            
            if df.empty:
                self.log(f"ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
                return None
            
            self.log(f"ì „ì²´ ë°ì´í„°: {len(df)}ê°œ ìƒ˜í”Œ")
            
            # Pythonì—ì„œ 5ì´ˆ ìœˆë„ìš°ë¡œ ë¶„í• 
            features_list = []
            
            # ì‹œê°„ì„ datetimeìœ¼ë¡œ ë³€í™˜
            df['time'] = pd.to_datetime(df['time'])
            
            # 5ì´ˆ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”
            df['window'] = df['time'].dt.floor(f'{window_sec}S')
            
            # ìœˆë„ìš°ë³„ë¡œ ì²˜ë¦¬
            window_count = 0
            for window, group in df.groupby('window'):
                # ìµœì†Œ 40ê°œ ì´ìƒ (80%) ë°ì´í„°ê°€ ìˆëŠ” ìœˆë„ìš°ë§Œ ì‚¬ìš©
                if len(group) >= window_samples * 0.8:  
                    try:
                        if sensor == 'acc':
                            features = self.extract_features_acc(
                                group['x'].values,
                                group['y'].values,
                                group['z'].values
                            )
                        else:
                            features = self.extract_features_mic(group['mic_value'].values)
                        
                        features_list.append(features)
                        window_count += 1
                        
                        # ì§„í–‰ ìƒí™© ë¡œê·¸ (1000ê°œë§ˆë‹¤)
                        if window_count % 1000 == 0:
                            self.log(f"  ì²˜ë¦¬ëœ ìœˆë„ìš°: {window_count}ê°œ")
                            
                    except Exception as e:
                        self.log(f"  ìœˆë„ìš° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        continue
            
            self.log(f"ì¶”ì¶œëœ ìœˆë„ìš°: {len(features_list)}ê°œ")
            
            return np.array(features_list) if features_list else None
            
        except Exception as e:
            self.log(f"ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None
    
    def train_model(self):
        """ëª¨ë¸ í•™ìŠµ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)"""
        try:
            machine_id = self.machine_var.get()
            sensor = self.sensor_var.get()
            n_trials = self.trials_var.get()
            
            self.log(f"\n{'='*60}")
            self.log(f"{machine_id} / {sensor} ëª¨ë¸ í•™ìŠµ ì‹œì‘")
            self.log(f"{'='*60}")
            
            # í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
            all_features = []
            period_info = []  # ê° ê¸°ê°„ë³„ ì •ë³´ ì €ì¥
            
            for start, end in self.training_periods:
                self.progress_var.set(f"ë°ì´í„° ì¶”ì¶œ ì¤‘: {start} ~ {end}")
                features = self.get_training_data(machine_id, sensor, start, end)
                if features is not None and len(features) > 0:
                    all_features.append(features)
                    period_info.append({
                        'period': f"{start} ~ {end}",
                        'start_idx': len(np.vstack(all_features[:-1])) if len(all_features) > 1 else 0,
                        'end_idx': len(np.vstack(all_features)),
                        'count': len(features)
                    })
                    self.log(f"âœ… {start} ~ {end}: {len(features)}ê°œ ìœˆë„ìš°")
            
            if not all_features:
                self.log("âŒ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                self.progress_var.set("í•™ìŠµ ë°ì´í„° ì—†ìŒ")
                return
            
            X_train = np.vstack(all_features)
            self.log(f"ì „ì²´ í•™ìŠµ ë°ì´í„°: {X_train.shape}")
            
            # ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ
            self.progress_var.set("ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ ì¤‘...")
            scaler = CustomRobustScaler()
            X_scaled = scaler.fit_transform(X_train)
            self.log("âœ… ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ ì™„ë£Œ")
            
            # OCSVM ìµœì í™”
            self.progress_var.set(f"í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì¤‘... (0/{n_trials})")
            
            opt_config = self.sensor_config[sensor]
            nu_range = opt_config['nu_range']
            gamma_range = opt_config['gamma_range']
            
            # ì‹œê°„ì  ë¶„í¬ë¥¼ ê³ ë ¤í•œ ê³„ì¸µì  ìƒ˜í”Œë§
            target_sample_size = min(20000, int(len(X_scaled) * 0.1))  # ìµœëŒ€ 20,000ê°œ
            
            if target_sample_size < len(X_scaled):
                self.log(f"\nğŸ“Š ê³„ì¸µì  ìƒ˜í”Œë§ ì‹œì‘: {len(X_scaled)}ê°œ â†’ {target_sample_size}ê°œ")
                
                sample_indices = []
                
                # ê° ê¸°ê°„ë³„ë¡œ ë¹„ë¡€ì ìœ¼ë¡œ ìƒ˜í”Œë§
                for info in period_info:
                    period_ratio = info['count'] / len(X_scaled)
                    period_sample_size = int(target_sample_size * period_ratio)
                    
                    if period_sample_size > 0:
                        # í•´ë‹¹ ê¸°ê°„ ë‚´ì—ì„œ ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§
                        period_indices = np.arange(info['start_idx'], info['end_idx'])
                        
                        if period_sample_size < len(period_indices):
                            # ì‹œê°„ ê°„ê²©ì„ ë‘ê³  ê· ë“±í•˜ê²Œ ì„ íƒ
                            step = len(period_indices) // period_sample_size
                            selected = period_indices[::step][:period_sample_size]
                        else:
                            selected = period_indices
                        
                        sample_indices.extend(selected)
                        self.log(f"  - {info['period']}: {len(selected)}ê°œ ìƒ˜í”Œ")
                
                sample_indices = np.array(sample_indices)
                X_sample = X_scaled[sample_indices]
                self.log(f"âœ… ì´ {len(X_sample)}ê°œ ìƒ˜í”Œ ì¶”ì¶œ ì™„ë£Œ")
            else:
                X_sample = X_scaled
                self.log(f"ğŸ“Š ë°ì´í„°ê°€ ì¶©ë¶„íˆ ì‘ì•„ ì „ì²´ ì‚¬ìš©: {len(X_scaled)}ê°œ")
            
            # study ë³€ìˆ˜ë¥¼ í´ë˜ìŠ¤ ë³€ìˆ˜ë¡œ ë§Œë“¤ì–´ objective í•¨ìˆ˜ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ
            self.study = create_study(direction='maximize')
            
            def objective(trial):
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                current_trial = len(self.study.trials)
                self.progress_var.set(f"í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì¤‘... ({current_trial}/{n_trials})")
                
                nu = trial.suggest_float('nu', nu_range[0], nu_range[1], log=True)
                gamma = trial.suggest_float('gamma', gamma_range[0], gamma_range[1], log=True)
                
                model = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma)
                model.fit(X_sample)
                
                scores = model.decision_function(X_sample)
                threshold = np.percentile(scores, 5)
                predictions = (scores > threshold).astype(int)
                accuracy = np.mean(predictions)
                
                return accuracy
            
            self.study.optimize(objective, n_trials=n_trials)
            
            best_params = self.study.best_params
            self.log(f"âœ… ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")
            
            # ìµœì¢… ëª¨ë¸ í•™ìŠµ
            self.progress_var.set("ìµœì¢… ëª¨ë¸ í•™ìŠµ ì¤‘...")
            model = OneClassSVM(
                kernel='rbf',
                nu=best_params['nu'],
                gamma=best_params['gamma']
            )
            model.fit(X_scaled)
            
            # ê²°ì • ê²½ê³„ ê³„ì‚°
            scores = model.decision_function(X_scaled)
            decision_boundary = float(np.percentile(scores, 5))
            
            # ëª¨ë¸ ì •ë³´
            model_info = {
                'machine_id': machine_id,
                'sensor': sensor,
                'train_samples': len(X_train),
                'training_periods': self.training_periods,
                'features': self.sensor_config[sensor]['features'],
                'best_params': best_params,
                'decision_boundary': decision_boundary,
                'score_statistics': {
                    'mean': float(np.mean(scores)),
                    'std': float(np.std(scores)),
                    'min': float(np.min(scores)),
                    'max': float(np.max(scores))
                },
                'trained_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            # ëª¨ë¸ ì €ì¥
            timestamp = datetime.now().strftime('%y%m%d_%H%M%S')
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            model_dir = f"./models/{machine_id}/{sensor}/current_model"
            scale_dir = f"./models/{machine_id}/{sensor}/current_scale"
            os.makedirs(model_dir, exist_ok=True)
            os.makedirs(scale_dir, exist_ok=True)
            
            # ê¸°ì¡´ íŒŒì¼ ì‚­ì œ
            for d in [model_dir, scale_dir]:
                for f in os.listdir(d):
                    os.remove(os.path.join(d, f))
            
            # ìƒˆ íŒŒì¼ ì €ì¥
            model_path = os.path.join(model_dir, f"{timestamp}_model.pkl")
            scaler_path = os.path.join(scale_dir, f"{timestamp}_scaler.pkl")
            info_path = os.path.join(model_dir, f"{timestamp}_model_info.json")
            
            joblib.dump(model, model_path)
            scaler.save(scaler_path)
            
            with open(info_path, 'w') as f:
                json.dump(model_info, f, indent=2)
            
            self.log(f"\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ:")
            self.log(f"  - ëª¨ë¸: {model_path}")
            self.log(f"  - ìŠ¤ì¼€ì¼ëŸ¬: {scaler_path}")
            self.log(f"  - ì •ë³´: {info_path}")
            
            # í˜„ì¬ ëª¨ë¸ ì •ë³´ ì €ì¥
            self.current_model_info = model_info
            
            self.progress_var.set("í•™ìŠµ ì™„ë£Œ!")
            messagebox.showinfo("ì™„ë£Œ", "ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            self.log(f"âŒ í•™ìŠµ ì‹¤íŒ¨: {e}")
            self.progress_var.set("í•™ìŠµ ì‹¤íŒ¨")
            messagebox.showerror("ì˜¤ë¥˜", f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            self.train_button.config(state='normal')
    
    def start_training(self):
        if not self.training_periods:
            messagebox.showerror("ì˜¤ë¥˜", "í•™ìŠµ ê¸°ê°„ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            return
        
        if not self.conn:
            messagebox.showerror("ì˜¤ë¥˜", "DB ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        self.train_button.config(state='disabled')
        thread = threading.Thread(target=self.train_model)
        thread.daemon = True
        thread.start()
    
    def test_model(self):
        """ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        try:
            # ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ í™•ì¸
            model_path = self.model_file_var.get()
            scaler_path = self.scaler_file_var.get()
            
            if not model_path or not scaler_path:
                messagebox.showerror("ì˜¤ë¥˜", "ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return
            
            if not os.path.exists(model_path) or not os.path.exists(scaler_path):
                messagebox.showerror("ì˜¤ë¥˜", "ì„ íƒí•œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return
            
            # ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
            self.log("ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì¤‘...")
            model = joblib.load(model_path)
            
            scaler = CustomRobustScaler()
            scaler.load(scaler_path)
            
            # ëª¨ë¸ ì •ë³´ ë¡œë“œ
            info_path = model_path.replace('_model.pkl', '_model_info.json')
            if os.path.exists(info_path):
                with open(info_path, 'r') as f:
                    model_info = json.load(f)
            else:
                # ê¸°ë³¸ ì •ë³´ ì‚¬ìš©
                model_info = {
                    'decision_boundary': -5.0,
                    'sensor': self.test_sensor_var.get()
                }
            
            # í…ŒìŠ¤íŠ¸ ì„¤ì •
            machine_id = self.test_machine_var.get()
            sensor = self.test_sensor_var.get()
            
            # ì„¼ì„œë³„ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì„ íƒ
            table_name = f"normal_{sensor}_data"
            
            self.result_text.delete(1.0, tk.END)
            self.result_text.insert(tk.END, f"ëª¨ë¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼\n")
            self.result_text.insert(tk.END, f"{'='*60}\n")
            self.result_text.insert(tk.END, f"ë¨¸ì‹ : {machine_id}, ì„¼ì„œ: {sensor}\n")
            self.result_text.insert(tk.END, f"í…Œì´ë¸”: {table_name}\n")
            self.result_text.insert(tk.END, f"ìƒ˜í”Œë§: {self.sampling_info_var.get()}\n")
            self.result_text.insert(tk.END, f"ê²°ì • ê²½ê³„: {model_info.get('decision_boundary', 'N/A')}\n\n")
            
            for test_date in self.test_periods:
                self.result_text.insert(tk.END, f"\n[{test_date}]\n")
                
                # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ (ë¼ì¦ˆë² ë¦¬íŒŒì´ì™€ ë™ì¼í•œ ë°©ì‹)
                test_data = self.get_training_data(
                    machine_id, sensor,
                    f"{test_date} 00:00:00",
                    f"{test_date} 23:59:59"
                )
                
                if test_data is None or len(test_data) == 0:
                    self.result_text.insert(tk.END, "  - ë°ì´í„° ì—†ìŒ\n")
                    continue
                
                # ì˜ˆì¸¡
                X_test_scaled = scaler.transform(test_data)
                predictions = model.predict(X_test_scaled)
                scores = model.decision_function(X_test_scaled)
                
                # ê²°ê³¼ ë¶„ì„
                anomaly_count = np.sum(predictions == -1)
                anomaly_ratio = anomaly_count / len(predictions) * 100
                
                self.result_text.insert(tk.END, f"  - ìƒ˜í”Œ ìˆ˜: {len(test_data)}\n")
                self.result_text.insert(tk.END, f"  - ì´ìƒ íƒì§€: {anomaly_count}ê°œ ({anomaly_ratio:.1f}%)\n")
                self.result_text.insert(tk.END, f"  - ì ìˆ˜: í‰ê· ={np.mean(scores):.3f}, ")
                self.result_text.insert(tk.END, f"ìµœì†Œ={np.min(scores):.3f}, ìµœëŒ€={np.max(scores):.3f}\n")
                
                # ì ìˆ˜ ë¶„í¬
                self.result_text.insert(tk.END, f"  - ì ìˆ˜ < 0: {np.sum(scores < 0)}ê°œ\n")
                self.result_text.insert(tk.END, f"  - ì ìˆ˜ < -5: {np.sum(scores < -5)}ê°œ\n")
                self.result_text.insert(tk.END, f"  - ì ìˆ˜ < -10: {np.sum(scores < -10)}ê°œ\n")
                
                # ê²°ì • ê²½ê³„ ê¸°ì¤€ ì´ìƒ íƒì§€
                if 'decision_boundary' in model_info:
                    boundary = model_info['decision_boundary']
                    below_boundary = np.sum(scores < boundary)
                    self.result_text.insert(tk.END, f"  - ì ìˆ˜ < {boundary:.3f} (ê²°ì •ê²½ê³„): {below_boundary}ê°œ\n")
                
            self.result_text.insert(tk.END, f"\n{'='*60}\n")
            self.result_text.insert(tk.END, "í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n")
            
        except Exception as e:
            messagebox.showerror("ì˜¤ë¥˜", f"í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def start_testing(self):
        if not self.test_periods:
            messagebox.showerror("ì˜¤ë¥˜", "í…ŒìŠ¤íŠ¸ ë‚ ì§œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            return
        
        thread = threading.Thread(target=self.test_model)
        thread.daemon = True
        thread.start()

def main():
    root = tk.Tk()
    app = OCSVMTrainerGUI(root)
    root.mainloop()

if __name__ == "__main__":
    main()