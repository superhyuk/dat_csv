#!/usr/bin/env python
# manual_s3_up.py
#ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ì—…ë¡œë“œ í•˜ê¸° ìœ„í•œ íŒŒì¼ì¼
import boto3
import os
from common_utils import load_aws_config, load_config

def upload_current_models():
    # AWS ì„¤ì •
    aws_cfg = load_aws_config()
    s3 = boto3.client('s3',
        aws_access_key_id=aws_cfg["access_key"],
        aws_secret_access_key=aws_cfg["secret_key"],
        region_name=aws_cfg["region"]
    )
    
    # í˜„ì¬ ë¨¸ì‹  ID
    config = load_config()
    machine_id = config.get("machine_id")
    bucket = aws_cfg["bucket_name"]
    
    # ì—…ë¡œë“œí•  í´ë”ë“¤
    base_path = "/home/kks/PDM_RUN/models"
    sensors = ["mic", "acc"]
    folders = ["current_model", "current_scaler"]
    
    # ì—…ë¡œë“œí•  íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
    files_to_upload = []
    
    for sensor in sensors:
        for folder in folders:
            folder_path = os.path.join(base_path, sensor, folder)
            
            if not os.path.exists(folder_path):
                print(f"âš ï¸  í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {folder_path}")
                continue
                
            # í´ë” ë‚´ íŒŒì¼ë“¤ í™•ì¸
            for root, dirs, files in os.walk(folder_path):
                for file in files:
                    local_file = os.path.join(root, file)
                    # ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
                    relative_path = os.path.relpath(local_file, base_path)
                    s3_key = f"{machine_id}/manual_upload/{relative_path}"
                    
                    files_to_upload.append({
                        'local': local_file,
                        's3_key': s3_key,
                        'size': os.path.getsize(local_file)
                    })
    
    if not files_to_upload:
        print("âŒ ì—…ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì—…ë¡œë“œí•  íŒŒì¼ ëª©ë¡ í‘œì‹œ
    print(f"\nğŸ“¤ ì—…ë¡œë“œí•  íŒŒì¼ ëª©ë¡ ({len(files_to_upload)}ê°œ):")
    print("-" * 80)
    total_size = 0
    
    for idx, file_info in enumerate(files_to_upload, 1):
        size_mb = file_info['size'] / (1024 * 1024)
        print(f"{idx:3d}. {os.path.basename(file_info['local']):30s} ({size_mb:6.2f} MB)")
        print(f"     â†’ s3://{bucket}/{file_info['s3_key']}")
        total_size += file_info['size']
    
    print("-" * 80)
    print(f"ì´ í¬ê¸°: {total_size / (1024 * 1024):.2f} MB")
    
    # ì—…ë¡œë“œ í™•ì¸
    confirm = input("\nëª¨ë“  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    if confirm.lower() != 'y':
        print("âŒ ì—…ë¡œë“œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return
    
    # íŒŒì¼ ì—…ë¡œë“œ
    print(f"\nğŸš€ S3 ì—…ë¡œë“œ ì‹œì‘...")
    success_count = 0
    failed_files = []
    
    for idx, file_info in enumerate(files_to_upload, 1):
        try:
            print(f"\n[{idx}/{len(files_to_upload)}] ì—…ë¡œë“œ ì¤‘: {os.path.basename(file_info['local'])}")
            print(f"  í¬ê¸°: {file_info['size'] / (1024 * 1024):.2f} MB")
            print(f"  ëŒ€ìƒ: s3://{bucket}/{file_info['s3_key']}")
            
            # S3 ì—…ë¡œë“œ
            s3.upload_file(
                file_info['local'],
                bucket,
                file_info['s3_key']
            )
            
            print(f"  âœ… ì—…ë¡œë“œ ì™„ë£Œ!")
            success_count += 1
            
        except Exception as e:
            print(f"  âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            failed_files.append(file_info['local'])
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print(f"ğŸ“Š ì—…ë¡œë“œ ê²°ê³¼:")
    print(f"  - ì„±ê³µ: {success_count}/{len(files_to_upload)}")
    print(f"  - ì‹¤íŒ¨: {len(failed_files)}")
    
    if failed_files:
        print(f"\nâŒ ì‹¤íŒ¨í•œ íŒŒì¼:")
        for file in failed_files:
            print(f"  - {file}")
    else:
        print(f"\nâœ… ëª¨ë“  íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"   S3 ê²½ë¡œ: s3://{bucket}/{machine_id}/manual_upload/")

if __name__ == "__main__":
    try:
        upload_current_models()
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")